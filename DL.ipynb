{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "ZDvrUIblHagE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "zpMYp7jpDWVf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "Y6oRivlUHetz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Load and Preprocess Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CSV, skip header\n",
        "dataset = pd.read_csv('GCseq25.csv', sep=',', skiprows=1)\n",
        "\n",
        "# Extract label (SNI) and features (packet size sequence)\n",
        "y = dataset.iloc[:, 0]             # Column 0 = SNI (label)\n",
        "X = dataset.iloc[:, 1:]            # Columns 1-100 = packet size values\n",
        "\n",
        "# Normalize features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Keep only the top N most frequent classes\n",
        "N = 25  # You can adjust this\n",
        "top_classes = pd.Series(y).value_counts().nlargest(N).index\n",
        "\n",
        "# Filter rows that belong to the top N classes\n",
        "filtered_indices = y.isin(top_classes)\n",
        "X_top = X_scaled[filtered_indices]\n",
        "y_top = y[filtered_indices]\n",
        "\n",
        "# Encode labels (string → integer → one-hot)\n",
        "label_encoder = LabelEncoder()\n",
        "y_top_encoded = label_encoder.fit_transform(y_top)\n",
        "y_top_categorical = to_categorical(y_top_encoded)\n",
        "\n",
        "# Train/test split with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_top, y_top_categorical, test_size=0.2, random_state=42, stratify=y_top_encoded\n",
        ")\n",
        "\n",
        "# Logging\n",
        "print(f\"Filtered to top {N} classes\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"Number of classes: {y_top_categorical.shape[1]}\")\n",
        "\n",
        "# Optional: print class names\n",
        "print(\"\\nClasses included (Top N SNIs):\")\n",
        "for idx, class_name in enumerate(label_encoder.classes_):\n",
        "    print(f\"Class {idx}: {class_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Afh2n1uADewQ",
        "outputId": "7cea637d-1864-4cee-d2c5-3e8588df5ae5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered to top 25 classes\n",
            "X_train shape: (5897, 100)\n",
            "y_train shape: (5897, 25)\n",
            "Number of classes: 25\n",
            "\n",
            "Classes included (Top N SNIs):\n",
            "Class 0: ads.yahoo.com\n",
            "Class 1: ae.akamai.net\n",
            "Class 2: assets.adobedtm.com\n",
            "Class 3: beacon.krxd.net\n",
            "Class 4: c.betrad.com\n",
            "Class 5: cdn.nhadatso.com\n",
            "Class 6: clients.google.com\n",
            "Class 7: d.adroll.com\n",
            "Class 8: dt.adsafeprotected.com\n",
            "Class 9: facebook.com\n",
            "Class 10: fls.doubleclick.net\n",
            "Class 11: google.com\n",
            "Class 12: google.fr\n",
            "Class 13: gstatic.com\n",
            "Class 14: ib.adnxs.com\n",
            "Class 15: l.betrad.com\n",
            "Class 16: mc.yandex.ru\n",
            "Class 17: nexus.ensighten.com\n",
            "Class 18: p.rfihub.com\n",
            "Class 19: pixel.quantserve.com\n",
            "Class 20: s.adroll.com\n",
            "Class 21: secure.adnxs.com\n",
            "Class 22: ssl.gstatic.com\n",
            "Class 23: staticxx.facebook.com\n",
            "Class 24: tags.tiqcdn.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_rf = np.argmax(y_train, axis=1)\n",
        "y_test_rf = np.argmax(y_test, axis=1)\n"
      ],
      "metadata": {
        "id": "-FsLBsH4Dtbj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "VN0TzeoXHkFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "cfiBxnfauB2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train_rf)\n",
        "rf_proba = rf_model.predict_proba(X_test)  # shape: (samples, num_classes)\n"
      ],
      "metadata": {
        "id": "6u_h44wXD0M6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape input to (samples, timesteps, features)\n",
        "# Treat each sample as 100 time steps with 1 feature per step\n",
        "X_train_seq = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_seq = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "print(\"X_train_seq shape:\", X_train_seq.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMZcfAm2EC1W",
        "outputId": "44b6c746-cfd8-492e-d0c7-a63f24284193"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_seq shape: (5897, 100, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Learning (LSTM)"
      ],
      "metadata": {
        "id": "8O6D3h5xuHfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "\n",
        "cnn_lstm = Sequential([\n",
        "    Conv1D(64, 3, activation='relu', input_shape=(100, 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(y_train.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "cnn_lstm.fit(X_train_seq, y_train, validation_split=0.1, epochs=20, batch_size=128)\n",
        "cnn_proba = cnn_lstm.predict(X_test_seq)  # shape: (samples, num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8y0OfoKD4ix",
        "outputId": "357c8d0b-cdcb-4893-f601-eefe054e8df0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 113ms/step - accuracy: 0.1368 - loss: 3.1313 - val_accuracy: 0.1898 - val_loss: 2.9145\n",
            "Epoch 2/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.1885 - loss: 2.9620 - val_accuracy: 0.1898 - val_loss: 2.8697\n",
            "Epoch 3/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.2039 - loss: 2.8524 - val_accuracy: 0.2542 - val_loss: 2.5764\n",
            "Epoch 4/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.2914 - loss: 2.5138 - val_accuracy: 0.2881 - val_loss: 2.2195\n",
            "Epoch 5/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.3528 - loss: 2.1904 - val_accuracy: 0.4305 - val_loss: 1.9594\n",
            "Epoch 6/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - accuracy: 0.4031 - loss: 2.0127 - val_accuracy: 0.4729 - val_loss: 1.8338\n",
            "Epoch 7/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4514 - loss: 1.8881 - val_accuracy: 0.5051 - val_loss: 1.7159\n",
            "Epoch 8/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.4839 - loss: 1.7600 - val_accuracy: 0.5322 - val_loss: 1.6075\n",
            "Epoch 9/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.4853 - loss: 1.7034 - val_accuracy: 0.5305 - val_loss: 1.5448\n",
            "Epoch 10/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.5140 - loss: 1.6373 - val_accuracy: 0.5593 - val_loss: 1.4599\n",
            "Epoch 11/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - accuracy: 0.5213 - loss: 1.5739 - val_accuracy: 0.5797 - val_loss: 1.3977\n",
            "Epoch 12/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5321 - loss: 1.5152 - val_accuracy: 0.6186 - val_loss: 1.3357\n",
            "Epoch 13/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.5662 - loss: 1.4006 - val_accuracy: 0.6220 - val_loss: 1.2645\n",
            "Epoch 14/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.5825 - loss: 1.3657 - val_accuracy: 0.6390 - val_loss: 1.2409\n",
            "Epoch 15/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.5900 - loss: 1.3300 - val_accuracy: 0.6203 - val_loss: 1.2301\n",
            "Epoch 16/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.5927 - loss: 1.3065 - val_accuracy: 0.6492 - val_loss: 1.1827\n",
            "Epoch 17/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.5934 - loss: 1.2845 - val_accuracy: 0.6458 - val_loss: 1.1574\n",
            "Epoch 18/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.5995 - loss: 1.2378 - val_accuracy: 0.6610 - val_loss: 1.1262\n",
            "Epoch 19/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.6126 - loss: 1.1996 - val_accuracy: 0.6797 - val_loss: 1.1020\n",
            "Epoch 20/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.6252 - loss: 1.1760 - val_accuracy: 0.6610 - val_loss: 1.1261\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure both predictions are aligned in shape\n",
        "assert rf_proba.shape == cnn_proba.shape\n",
        "\n",
        "# Average predicted probabilities\n",
        "ensemble_proba = (rf_proba + cnn_proba) / 2\n",
        "ensemble_pred = np.argmax(ensemble_proba, axis=1)\n"
      ],
      "metadata": {
        "id": "XlEotvMGE0kH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "ensemble_accuracy = accuracy_score(y_test_rf, ensemble_pred)\n",
        "print(f\"\\n🧠 Hybrid RF + CNN-LSTM Ensemble Accuracy: {ensemble_accuracy * 100:.2f}%\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_rf, ensemble_pred, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hysxjeVTE29y",
        "outputId": "3968cfa0-8787-46a8-8b9a-1a2f8199ef94"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧠 Hybrid RF + CNN-LSTM Ensemble Accuracy: 90.71%\n",
            "\n",
            "Classification Report:\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "         ads.yahoo.com       0.86      0.94      0.90        34\n",
            "         ae.akamai.net       0.93      0.82      0.87        33\n",
            "   assets.adobedtm.com       0.73      0.59      0.66        32\n",
            "       beacon.krxd.net       1.00      0.91      0.95        32\n",
            "          c.betrad.com       0.84      0.94      0.88        65\n",
            "      cdn.nhadatso.com       0.95      1.00      0.97        37\n",
            "    clients.google.com       0.86      0.97      0.91        37\n",
            "          d.adroll.com       0.93      0.96      0.95        85\n",
            "dt.adsafeprotected.com       0.92      0.97      0.94        34\n",
            "          facebook.com       0.97      0.89      0.93        66\n",
            "   fls.doubleclick.net       0.98      0.98      0.98        56\n",
            "            google.com       0.91      0.94      0.93        33\n",
            "             google.fr       1.00      0.97      0.98       177\n",
            "           gstatic.com       1.00      0.06      0.12        32\n",
            "          ib.adnxs.com       0.84      0.66      0.74        47\n",
            "          l.betrad.com       0.97      0.93      0.95        40\n",
            "          mc.yandex.ru       0.83      0.87      0.85        39\n",
            "   nexus.ensighten.com       1.00      0.79      0.89        34\n",
            "          p.rfihub.com       0.92      0.97      0.94        34\n",
            "  pixel.quantserve.com       0.95      0.93      0.94        41\n",
            "          s.adroll.com       0.73      0.50      0.59        32\n",
            "      secure.adnxs.com       0.79      0.93      0.86        91\n",
            "       ssl.gstatic.com       0.90      1.00      0.95       284\n",
            " staticxx.facebook.com       0.97      1.00      0.99        38\n",
            "       tags.tiqcdn.com       0.85      0.98      0.91        42\n",
            "\n",
            "              accuracy                           0.91      1475\n",
            "             macro avg       0.91      0.86      0.86      1475\n",
            "          weighted avg       0.91      0.91      0.90      1475\n",
            "\n"
          ]
        }
      ]
    }
  ]
}